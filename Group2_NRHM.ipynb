{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTf50UnwJwiG"
   },
   "source": [
    "# Importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbOqCKOfIYBJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Kqz5fiSKfHK"
   },
   "source": [
    "# **Dataset-1:** Analysis of Budget proposal and alllocation of all the states and UTs, from the fiscal year 2015-16 to 2022-2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0za9Pw8J0kF"
   },
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df1 = pd.read_csv(\"C:\\\\Users\\\\yashg\\\\OneDrive\\\\Desktop\\\\Group2\\\\nhm---july-2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "z03GDGakKU0x",
    "outputId": "63538e0a-af90-4042-fe65-6b7148c2f918"
   },
   "outputs": [],
   "source": [
    "# Displaying top 5 rows\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylALmVzpM6Hg"
   },
   "source": [
    "# Dropping the columns with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flkP93BBMciP"
   },
   "outputs": [],
   "source": [
    "# Dropping the columns with all NULL Values\n",
    "df1 = df1.drop(['Unnamed: 11',\n",
    "                        'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15',\n",
    "                        'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19',\n",
    "                        'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ncgu8FSSKdz0",
    "outputId": "8375c176-3dab-4512-b088-0c3d0bd18942"
   },
   "outputs": [],
   "source": [
    "# Displaying number of rows and columns\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0P0flHLV6Zj"
   },
   "outputs": [],
   "source": [
    "# Dropping the rows\n",
    "df1 = df1.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHP0EXZFdJFH",
    "outputId": "94b36888-86c7-4467-e154-00b42d083abb"
   },
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AA77ThhTdEKA",
    "outputId": "9f2bc943-c71e-4e10-a4a8-c3a2cf7abb99"
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6-ZGWA2dG2I",
    "outputId": "0f23dfde-4162-474c-ab16-1c16806b55b7"
   },
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jnd3e9P1Ndkr",
    "outputId": "6d8abb02-5a65-4db5-8c0d-9ccd8db04500"
   },
   "outputs": [],
   "source": [
    "# Percentage of NULL values in each column\n",
    "df1.isnull().sum()*100/(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83Plkl9SNsXp",
    "outputId": "44a572ea-7390-4d08-875f-a15ae7e3741a"
   },
   "outputs": [],
   "source": [
    "# Displaying all column names:\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmStpSpUQyDL",
    "outputId": "feaa69e9-0d02-4ad3-e915-9f1f2193c3f5"
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "id": "MeIawdmbRsQ0",
    "outputId": "ebf4627d-dea0-46c5-837d-aaf904eecf8c"
   },
   "outputs": [],
   "source": [
    "# Replace 'NA' with NaN\n",
    "df1.replace('NA', np.nan, inplace=True)\n",
    "\n",
    "# Create a heatmap to visualize null values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df1.isnull(), cmap='viridis', cbar=False)\n",
    "plt.title('Null Values in Dataset')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Interpreting the Heatmap:\n",
    "# In the heatmap:\n",
    "# Yellow (or light color) cells represent missing (null) values.\n",
    "# Dark cells represent non-null values.\n",
    "# The heatmap allows you to quickly identify columns with missing data (yellow cells).\n",
    "# This visualization helps in understanding the completeness of your dataset and\n",
    "# deciding how to handle missing values during data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "K6sAozh3N5Ns",
    "outputId": "91aaf15c-4670-4d67-a365-0589696247a8"
   },
   "outputs": [],
   "source": [
    "# Budget Approved for the States/UTs\n",
    "\n",
    "df1['Budget Approved for the States/UTs  '].plot(kind='hist', bins=10, title='Budget Approved for the States/UTs  ')\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 794
    },
    "id": "Y0Meu41ZKG3u",
    "outputId": "0a6bda88-18d6-4482-c8bf-666840ddb198"
   },
   "outputs": [],
   "source": [
    "pivot_df = df1.pivot_table(index='Fiscal Year', columns='State_UT', values='Budget Approved for the States/UTs  ', aggfunc='mean')\n",
    "\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each state/UT as a separate line\n",
    "for state in pivot_df.columns:\n",
    "    sns.lineplot(x=pivot_df.index, y=pivot_df[state], label=state)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Budget Approved for States/UTs Over Financial Years')\n",
    "plt.xlabel('Fiscal Year')\n",
    "plt.ylabel('Budget Approved (in crore)')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  # Place legend outside the plot\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()\n",
    "\n",
    "# Line plot to visualize variation of budget approved for States/UTs over financial Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uxkTV7ruLmsP",
    "outputId": "04ee718d-b2af-4eb1-f1b7-5a21330d7046",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states = df1['State_UT'].unique()\n",
    "\n",
    "# Plot individual bar graphs for each state\n",
    "for state in states:\n",
    "    # Filter the DataFrame for the specific state\n",
    "    state_df = df1[df1['State_UT'] == state]\n",
    "\n",
    "    # Set up the plot for the current state\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot a bar graph for budget approved over fiscal years\n",
    "    sns.barplot(x='Fiscal Year', y='Budget Approved for the States/UTs  ', data=state_df)\n",
    "    plt.title(f'Budget Approved Over Fiscal Years for {state}')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel('Budget Approved (in crore)')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Reason for Ladakh not showing budget allocation before 2019 since Ladakh became a Union Territory in October 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1C90RkCFQ7L4",
    "outputId": "40460ce3-de5a-43d8-e086-3ffd88d85680"
   },
   "outputs": [],
   "source": [
    "# Get the list of unique states/UTs in the DataFrame\n",
    "states = df1['State_UT'].unique()\n",
    "\n",
    "# Plot individual visualizations for each state\n",
    "for state in states:\n",
    "    # Filter the DataFrame for the specific state\n",
    "    state_df = df1[df1['State_UT'] == state]\n",
    "\n",
    "    # Set up the plot for the current state\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot side-by-side bar chart for proposed vs. approved budgets over fiscal years\n",
    "    sns.barplot(x='Fiscal Year', y='Budget Proposed by the States/UTs', data=state_df, color='skyblue', alpha=0.7, label='Proposed')\n",
    "    sns.barplot(x='Fiscal Year', y='Budget Approved for the States/UTs  ', data=state_df, color='orange', alpha=0.7, label='Approved')\n",
    "\n",
    "    plt.title(f'Comparison of Proposed vs. Approved Budgets for {state}')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel('Budget (in crore)')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bBK0Gc_wZOyN",
    "outputId": "6da6d348-61e0-4e8e-a9a6-3804d9a6d606"
   },
   "outputs": [],
   "source": [
    "# Set up separate plots for each state\n",
    "states = df1['State_UT'].unique()  # Get unique states\n",
    "\n",
    "# Create a separate plot for each state\n",
    "for state in states:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Filter data for the current state\n",
    "    state_data = df1[df1['State_UT'] == state]\n",
    "\n",
    "    # Plot budget approved over fiscal years for the current state\n",
    "    sns.lineplot(x='Fiscal Year', y='Budget Approved for the States/UTs  ', data=state_data, marker='o')\n",
    "\n",
    "    # Set title and labels\n",
    "    plt.title(f'Budget Approved for {state} Over Fiscal Years')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel('Budget Approved (in crore)')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Show plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "oX9F1NXIS3Hk",
    "outputId": "bf42de12-9c1a-490b-899c-f9b894d693b3"
   },
   "outputs": [],
   "source": [
    "total_budget_approved_per_year = df1.groupby('Fiscal Year')['Budget Approved for the States/UTs  '].sum()\n",
    "\n",
    "# Display the total budget approved for each financial year\n",
    "print(\"Total Budget Approved for Each Financial Year:\")\n",
    "print(total_budget_approved_per_year)\n",
    "\n",
    "# Visualize the total budget approved per financial year\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=total_budget_approved_per_year.index, y=total_budget_approved_per_year.values, palette='muted')\n",
    "plt.title('Total Budget Approved per Financial Year')\n",
    "plt.xlabel('Financial Year')\n",
    "plt.ylabel('Total Budget Approved (in crore)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "w3ZaUIs5bmnZ",
    "outputId": "29c2cd0e-33f3-47cd-b28c-366bfe9de4f0"
   },
   "outputs": [],
   "source": [
    "# Function to plot opening balance with bars pointing up or down based on sign\n",
    "def plot_opening_balance(state_data):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Plot bar chart with custom color based on value sign\n",
    "    colors = ['red' if x < 0 else 'green' for x in state_data['Opening Balance with the States/UTs']]\n",
    "    plt.bar(state_data['Fiscal Year'], state_data['Opening Balance with the States/UTs'], color=colors)\n",
    "\n",
    "    # Set title and labels\n",
    "    plt.title(f'Opening Balance for {state_data[\"State_UT\"].iloc[0]} Over Fiscal Years')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel('Opening Balance (in crore)')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "# Group by state and plot opening balance for each state\n",
    "for state, state_data in df1.groupby('State_UT'):\n",
    "    plot_opening_balance(state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "2W3mmkC7oz-X",
    "outputId": "183e18e7-cae6-49bb-d8df-8b21578a8c49"
   },
   "outputs": [],
   "source": [
    "# Filter relevant columns for analysis\n",
    "data = df1[['Opening Balance with the States/UTs', 'Budget Approved for the States/UTs  ']]\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Extract correlation coefficient between Opening Balance and Approved Budget\n",
    "correlation_coefficient = correlation_matrix.loc['Opening Balance with the States/UTs', 'Budget Approved for the States/UTs  ']\n",
    "\n",
    "print(\"Correlation Coefficient between Opening Balance and Approved Budget:\")\n",
    "print(correlation_coefficient)\n",
    "\n",
    "# Create a scatter plot to visualize the relationship\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Opening Balance with the States/UTs', y='Budget Approved for the States/UTs  ', data=df1)\n",
    "plt.title('Relationship between Opening Balance and Approved Budget')\n",
    "plt.xlabel('Opening Balance (in crore)')\n",
    "plt.ylabel('Approved Budget (in crore)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EuPo47iPNv_K",
    "outputId": "675ead8d-f4e4-4b7c-f4b5-dae84a8dc1f8"
   },
   "outputs": [],
   "source": [
    "# To identify states/UTs where the approved budget is more than the proposed budget for each fiscal year in your dataset,\n",
    "\n",
    "# Filter the DataFrame to include states/UTs where Approved Budget > Proposed Budget for each fiscal year\n",
    "approved_greater_than_proposed = df1[df1['Budget Approved for the States/UTs  '] > df1['Budget Proposed by the States/UTs']]\n",
    "\n",
    "# Group the filtered DataFrame by Fiscal Year and list the states/UTs where Approved Budget > Proposed Budget\n",
    "states_by_year = approved_greater_than_proposed.groupby('Fiscal Year')['State_UT'].apply(list)\n",
    "\n",
    "# Display the states/UTs where Approved Budget > Proposed Budget for each fiscal year\n",
    "for year, states_list in states_by_year.items():\n",
    "    print(f\"For Fiscal Year {year}:\")\n",
    "    print(states_list)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "9XnPlQBpRwuS",
    "outputId": "33d3b5ad-bd75-40ff-ec08-ba484d78eeaa"
   },
   "outputs": [],
   "source": [
    "# calculate the average extent of budget approved against budget proposed across all states/UTs for each fiscal year\n",
    "\n",
    "\n",
    "# Group by Fiscal Year and calculate the average extent of budget approved against budget proposed\n",
    "average_approval_ratio_by_year = df1.groupby('Fiscal Year')['Extent of Budget Approved Against Budget Proposed '].mean()\n",
    "\n",
    "# Convert the grouped series to a DataFrame for plotting\n",
    "average_approval_ratio_df = average_approval_ratio_by_year.reset_index()\n",
    "\n",
    "# Plotting the average extent of budget approved against budget proposed for each fiscal year\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(average_approval_ratio_df['Fiscal Year'], average_approval_ratio_df['Extent of Budget Approved Against Budget Proposed '], color='skyblue')\n",
    "plt.title('Average Extent of Budget Approved Against Budget Proposed by Fiscal Year')\n",
    "plt.xlabel('Fiscal Year')\n",
    "plt.ylabel('Average Approval Ratio (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tFcyKQ9Pic0k",
    "outputId": "5a726ffb-b40b-444c-e016-e5bd43ab3735"
   },
   "outputs": [],
   "source": [
    "# Iterate over each state and create separate side-by-side bar charts\n",
    "for state in df1['State_UT'].unique():\n",
    "    state_data = df1[df1['State_UT'] == state]\n",
    "    fiscal_years = state_data['Fiscal Year'].unique()\n",
    "\n",
    "    # Set up the figure and axes for the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # Define the width of each bar (adjust as needed)\n",
    "    bar_width = 0.2\n",
    "    index = range(len(fiscal_years))\n",
    "\n",
    "    # Plotting each parameter as a separate set of bars\n",
    "    ax.bar(index, state_data['Budget Proposed by the States/UTs'], width=bar_width, label='Budget Proposed')\n",
    "    ax.bar([p + bar_width for p in index], state_data['Budget Approved for the States/UTs  '], width=bar_width, label='Budget Approved')\n",
    "    ax.bar([p + 2*bar_width for p in index], state_data[\"Release of Government of India's Fund \"], width=bar_width, label='Release of Funds')\n",
    "    ax.bar([p + 3*bar_width for p in index], state_data[\"Total Expenditure Reported (Including States' Share)\"], width=bar_width, label='Total Expenditure')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Fiscal Year')\n",
    "    ax.set_ylabel('Amount (in crore)')\n",
    "    ax.set_title(f'Variation of Parameters Over Fiscal Years - {state}')\n",
    "    ax.set_xticks([p + 1.5*bar_width for p in index])\n",
    "    ax.set_xticklabels(fiscal_years)\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot for the current state\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "ae7_4l8MS-TX",
    "outputId": "7ca02de2-0582-4940-973b-52d31e9310be"
   },
   "outputs": [],
   "source": [
    "# analyze how the release of Government of India's fund varies across different fiscal years and visualize this variation\n",
    "\n",
    "# Group by Fiscal Year and calculate the total release of Government of India's fund for each year\n",
    "total_fund_release_by_year = df1.groupby('Fiscal Year')['Release of Government of India\\'s Fund '].sum()\n",
    "\n",
    "# Convert the grouped series to a DataFrame for plotting\n",
    "total_fund_release_df = total_fund_release_by_year.reset_index()\n",
    "\n",
    "# Plotting the variation of Government of India's fund release across fiscal years\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(total_fund_release_df['Fiscal Year'], total_fund_release_df['Release of Government of India\\'s Fund '], marker='o', color='green', linestyle='-', linewidth=2)\n",
    "plt.title('Variation of Government of India\\'s Fund Release Across Fiscal Years')\n",
    "plt.xlabel('Fiscal Year')\n",
    "plt.ylabel('Total Fund Release (in crore)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rwZcjjsAng8a",
    "outputId": "f65451a0-47bc-4f66-b99e-4ed68f4b6dcc"
   },
   "outputs": [],
   "source": [
    "# visualize the distribution of budget proposed by different states/UTs for each fiscal year using pie charts.\n",
    "# Iterate over each fiscal year and plot a pie chart for budget distribution\n",
    "# Calculate total budget proposed by each state/UT for each fiscal year\n",
    "budget_by_state = df1.groupby(['Fiscal Year', 'State_UT'])['Budget Proposed by the States/UTs'].sum().unstack().fillna(0)\n",
    "\n",
    "# Set the number of top states/UTs to display in each pie chart\n",
    "top_n = 10\n",
    "# Define custom colors for pie chart slices (change or add colors as needed)\n",
    "custom_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf','#DFFF00']\n",
    "\n",
    "for fiscal_year in df1['Fiscal Year'].unique():\n",
    "    year_data = budget_by_state.loc[fiscal_year]\n",
    "\n",
    "    # Filter out states with zero budget proposed for the current fiscal year\n",
    "    year_data = year_data[year_data > 0]\n",
    "\n",
    "    # Sort states by budget proposed (descending order) for better visualization\n",
    "    year_data_sorted = year_data.sort_values(ascending=False)\n",
    "\n",
    "    # Get top N states and their budget proposed\n",
    "    top_states = year_data_sorted.head(top_n)\n",
    "    other_states = year_data_sorted.iloc[top_n:]\n",
    "\n",
    "\n",
    "    # Summing up budget proposed for other states\n",
    "    other_budget = other_states.sum()\n",
    "\n",
    "  # Combining top N states and \"Others\" into a new Series\n",
    "    pie_data = pd.concat([top_states, pd.Series({'Others': other_budget})])\n",
    "\n",
    "    # Plotting the pie chart with percentages and legend\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.pie(pie_data, labels=pie_data.index, autopct='%1.1f%%', startangle=140, colors=custom_colors)\n",
    "    plt.title(f'States/UTs - Budget Proposed Distribution ({fiscal_year})')\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "\n",
    "    # Add legend to the plot\n",
    "    plt.legend(title='States/UTs', loc='best', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Show the pie chart for the current fiscal year\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcMQ0IewQr0W"
   },
   "outputs": [],
   "source": [
    "# Replace 0 with NaN in specified columns\n",
    "columns_to_replace = ['Budget Proposed by the States/UTs', 'Budget Approved for the States/UTs  ',\"Release of Government of India's Fund \",\"Total Expenditure Reported (Including States' Share)\"]\n",
    "df1[columns_to_replace] = df1[columns_to_replace].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "fbDsUFglGk__",
    "outputId": "072b8473-d168-4ed3-d178-89b63127a21f"
   },
   "outputs": [],
   "source": [
    "df1[df1['State_UT'] == 'Ladakh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXRYw9jZqrFu"
   },
   "outputs": [],
   "source": [
    "# Dropping NULL values\n",
    "# Filter rows where State_UT is 'Ladakh' and Fiscal Year is before 2020\n",
    "mask = (df1['State_UT'] == 'Ladakh') & (df1['Fiscal Year'] < '2020-21')\n",
    "\n",
    "# Drop rows that match the condition\n",
    "df1.drop(df1[mask].index, inplace=True)\n",
    "\n",
    "# Reset index after dropping rows\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "dlh0zI0OGHwh",
    "outputId": "bd5ba4c5-2c51-441c-bca4-20eddb2dde29"
   },
   "outputs": [],
   "source": [
    "df1[df1['State_UT'] == 'Ladakh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4qP4qGEGyl5",
    "outputId": "06cd508e-6380-4697-97fd-b8bc972ad905"
   },
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWFmWkdxIgwp"
   },
   "outputs": [],
   "source": [
    "# Replace null values in the \"Budget Proposed\" column with the mean budget proposed for the same state over all years\n",
    "# Calculate mean budget proposed for each state\n",
    "state_mean_budget = df1.groupby('State_UT')['Budget Proposed by the States/UTs'].mean()\n",
    "\n",
    "# Function to fill missing values with state-wise mean\n",
    "def fill_missing_budget(row):\n",
    "    state = row['State_UT']\n",
    "    budget_proposed = row['Budget Proposed by the States/UTs']\n",
    "    if pd.isnull(budget_proposed):\n",
    "        return state_mean_budget[state]\n",
    "    else:\n",
    "        return budget_proposed\n",
    "\n",
    "# Apply the function to fill missing values in 'Budget_Proposed' column\n",
    "df1['Budget Proposed by the States/UTs'] = df1.apply(fill_missing_budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-tZzG3J0JLZy",
    "outputId": "169d3add-ae85-49a6-ac3a-daca9fdc330f"
   },
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbEPxItGJga2"
   },
   "outputs": [],
   "source": [
    "# Similarly replace NULL values for Budget Approved for the States/UTs ,Release of Government of India's Fund , Total Expenditure Reported                   3\n",
    "# Calculate mean budget proposed for each state\n",
    "state_mean_budget = df1.groupby('State_UT')['Budget Approved for the States/UTs  '].mean()\n",
    "\n",
    "# Function to fill missing values with state-wise mean\n",
    "def fill_missing_budget(row):\n",
    "    state = row['State_UT']\n",
    "    budget_proposed = row['Budget Approved for the States/UTs  ']\n",
    "    if pd.isnull(budget_proposed):\n",
    "        return state_mean_budget[state]\n",
    "    else:\n",
    "        return budget_proposed\n",
    "\n",
    "# Apply the function to fill missing values in 'Budget_Proposed' column\n",
    "df1['Budget Approved for the States/UTs  '] = df1.apply(fill_missing_budget, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCfvcC5_ObUV"
   },
   "outputs": [],
   "source": [
    "state_mean_budget = df1.groupby('State_UT')[\"Release of Government of India's Fund \"].mean()\n",
    "\n",
    "# Function to fill missing values with state-wise mean\n",
    "def fill_missing_budget(row):\n",
    "    state = row['State_UT']\n",
    "    budget_proposed = row[\"Release of Government of India's Fund \"]\n",
    "    if pd.isnull(budget_proposed):\n",
    "        return state_mean_budget[state]\n",
    "    else:\n",
    "        return budget_proposed\n",
    "\n",
    "# Apply the function to fill missing values in 'Budget_Proposed' column\n",
    "df1[\"Release of Government of India's Fund \"] = df1.apply(fill_missing_budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcLq05VEPABB"
   },
   "outputs": [],
   "source": [
    "state_mean_budget = df1.groupby('State_UT')[\"Total Expenditure Reported (Including States' Share)\"].mean()\n",
    "\n",
    "# Function to fill missing values with state-wise mean\n",
    "def fill_missing_budget(row):\n",
    "    state = row['State_UT']\n",
    "    budget_proposed = row[\"Total Expenditure Reported (Including States' Share)\"]\n",
    "    if pd.isnull(budget_proposed):\n",
    "        return state_mean_budget[state]\n",
    "    else:\n",
    "        return budget_proposed\n",
    "\n",
    "# Apply the function to fill missing values in 'Budget_Proposed' column\n",
    "df1[\"Total Expenditure Reported (Including States' Share)\"] = df1.apply(fill_missing_budget, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9MZeyEHMiNN",
    "outputId": "639a76e6-4b6c-4372-cb64-4a55fb3e444a"
   },
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnYFnuGXVozi"
   },
   "outputs": [],
   "source": [
    "# Define a function to fill null values in 'Extent_Budget_Approved_vs_Proposed'\n",
    "def fill_extent_approved_vs_proposed(row):\n",
    "    budget_proposed = row['Budget Proposed by the States/UTs']\n",
    "    budget_approved = row['Budget Approved for the States/UTs  ']\n",
    "    if pd.isnull(row['Extent of Budget Approved Against Budget Proposed ']):\n",
    "        if budget_proposed != 0:\n",
    "            return (budget_approved / budget_proposed) * 100\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return row['Extent of Budget Approved Against Budget Proposed ']\n",
    "\n",
    "# Define a function to fill null values in 'Extent_Funds_Utilised_vs_Approved'\n",
    "def fill_extent_utilised_vs_approved(row):\n",
    "    budget_approved = row['Budget Approved for the States/UTs  ']\n",
    "    expenditure = row[\"Total Expenditure Reported (Including States' Share)\"]\n",
    "    if pd.isnull(row['Extent of Funds Utilised Against Budget Approved']):\n",
    "        if budget_approved != 0:\n",
    "            return (expenditure / budget_approved) * 100\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return row['Extent of Funds Utilised Against Budget Approved']\n",
    "\n",
    "# Define a function to fill null values in 'Extent_Funds_Utilised_vs_Proposed'\n",
    "def fill_extent_utilised_vs_proposed(row):\n",
    "    budget_proposed = row['Budget Proposed by the States/UTs']\n",
    "    expenditure = row[\"Total Expenditure Reported (Including States' Share)\"]\n",
    "    if pd.isnull(row['Extent of Funds Utilised Against Budget Proposed ']):\n",
    "        if budget_proposed != 0:\n",
    "            return (expenditure / budget_proposed) * 100\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return row['Extent of Funds Utilised Against Budget Proposed ']\n",
    "\n",
    "# Apply the custom functions to fill null values in respective columns\n",
    "df1['Extent of Budget Approved Against Budget Proposed '] = df1.apply(fill_extent_approved_vs_proposed, axis=1)\n",
    "df1['Extent of Funds Utilised Against Budget Approved'] = df1.apply(fill_extent_utilised_vs_approved, axis=1)\n",
    "df1['Extent of Funds Utilised Against Budget Proposed '] = df1.apply(fill_extent_utilised_vs_proposed, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49Sogw-PVyqA",
    "outputId": "13cf5081-ec36-4a9a-c391-d59910fd846f"
   },
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKCCe3rsWh9j"
   },
   "outputs": [],
   "source": [
    "# Drop the column 'Opening Balance with the States/UTs'\n",
    "column_to_drop = 'Opening Balance with the States/UTs'\n",
    "df1.drop(column_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "id": "mfoczp8sSo5i",
    "outputId": "7da84bf2-0106-445d-c077-83f9a10a267b"
   },
   "outputs": [],
   "source": [
    "# Create a heatmap to visualize null values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df1.isnull(), cmap='viridis', cbar=False)\n",
    "plt.title('Null Values in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our data is complelety clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0MEqpFaSsgb"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy for our data \n",
    "df=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  perform one-hot encoding on categorical columns\n",
    "categorical_columns = ['State_UT', 'Fiscal Year']\n",
    "\n",
    "# Perform One-Hot Encoding using pd.get_dummies()\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Display the encoded DataFrame\n",
    "print(\"Encoded DataFrame:\")\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Standardization:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Separate numerical\n",
    "numerical_columns = ['Budget Proposed by the States/UTs','Budget Approved for the States/UTs  ',\"Release of Government of India's Fund \",\"Total Expenditure Reported (Including States' Share)\"]\n",
    "\n",
    "# Apply Standardization to Numerical Columns\n",
    "scaler = StandardScaler()\n",
    "df_encoded[numerical_columns] = scaler.fit_transform(df_encoded[numerical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop from df_encoded\n",
    "columns_to_drop = [\n",
    "    'State_UT_Code',\n",
    "    'Extent of Budget Approved Against Budget Proposed ',\n",
    "    'Extent of Funds Utilised Against Budget Approved',\n",
    "    'Extent of Funds Utilised Against Budget Proposed '\n",
    "]\n",
    "\n",
    "# Drop specified columns from df_encoded\n",
    "df_encoded = df_encoded.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numerical feature into categorical bins\n",
    "# Dividing the budget proposed by the states into low , medium, and high\n",
    "df1['Budget_Category'] = pd.cut(df1['Budget Proposed by the States/UTs'], bins=3, labels=['Low', 'Medium', 'High'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "# Assuming 'Budget Proposed by the States/UTs' is the column of interest in your DataFrame (df)\n",
    "column_name = 'Budget Proposed by the States/UTs'\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = skew(df1[column_name])\n",
    "\n",
    "# Print skewness value\n",
    "print(f\"Skewness of '{column_name}': {skewness:.2f}\")\n",
    "\n",
    "# Visualize the distribution using a histogram and density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df1[column_name], kde=True, color='blue', bins=30)\n",
    "plt.title(f'Distribution of \"{column_name}\" (Skewness: {skewness:.2f})')\n",
    "plt.xlabel(column_name)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Determine distribution type based on skewness\n",
    "if skewness > 0:\n",
    "    print(f\"'{column_name}' has a right-skewed distribution (positive skewness)\")\n",
    "elif skewness < 0:\n",
    "    print(f\"'{column_name}' has a left-skewed distribution (negative skewness)\")\n",
    "else:\n",
    "    print(f\"'{column_name}' has an approximately symmetric distribution (skewness close to 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Budget_proposed_Log_Transformed'] = np.log1p(df1['Budget Proposed by the States/UTs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'Budget_proposed_Log_Transformed'\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = skew(df1[column_name])\n",
    "\n",
    "# Print skewness value\n",
    "print(f\"Skewness of '{column_name}': {skewness:.2f}\")\n",
    "\n",
    "# Visualize the distribution using a histogram and density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df1[column_name], kde=True, color='blue', bins=30)\n",
    "plt.title(f'Distribution of \"{column_name}\" (Skewness: {skewness:.2f})')\n",
    "plt.xlabel(column_name)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Determine distribution type based on skewness\n",
    "if skewness > 0:\n",
    "    print(f\"'{column_name}' has a right-skewed distribution (positive skewness)\")\n",
    "elif skewness < 0:\n",
    "    print(f\"'{column_name}' has a left-skewed distribution (negative skewness)\")\n",
    "else:\n",
    "    print(f\"'{column_name}' has an approximately symmetric distribution (skewness close to 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Budget_proposed_SquareRoot_Transformed'] = np.sqrt(df['Budget Proposed by the States/UTs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "column_name = 'Budget_proposed_SquareRoot_Transformed'\n",
    "\n",
    "# Calculate skewness\n",
    "skewness = skew(df1[column_name])\n",
    "\n",
    "# Print skewness value\n",
    "print(f\"Skewness of '{column_name}': {skewness:.2f}\")\n",
    "\n",
    "# Visualize the distribution using a histogram and density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df1[column_name], kde=True, color='blue', bins=30)\n",
    "plt.title(f'Distribution of \"{column_name}\" (Skewness: {skewness:.2f})')\n",
    "plt.xlabel(column_name)\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Determine distribution type based on skewness\n",
    "if skewness > 0:\n",
    "    print(f\"'{column_name}' has a right-skewed distribution (positive skewness)\")\n",
    "elif skewness < 0:\n",
    "    print(f\"'{column_name}' has a left-skewed distribution (negative skewness)\")\n",
    "else:\n",
    "    print(f\"'{column_name}' has an approximately symmetric distribution (skewness close to 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Feature Selection:\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Visualize the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify features with highest absolute correlation with the target variable\n",
    "target_correlation = correlation_matrix[\"Total Expenditure Reported (Including States' Share)\"].abs().sort_values(ascending=False)\n",
    "important_features = target_correlation[target_correlation >= 0.5].index.tolist()\n",
    "print(\"Important Features based on Correlation:\")\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Define features (X) and target variable (y)\n",
    "X = df_encoded.drop(\"Total Expenditure Reported (Including States' Share)\", axis=1)\n",
    "y = df_encoded[\"Total Expenditure Reported (Including States' Share)\"]\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train LinearRegression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance (e.g., using Mean Squared Error for regression)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot of predicted vs. actual values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)\n",
    "plt.title('Predicted vs. Actual Values (Linear Regression)')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize SVR model\n",
    "svr_model = SVR(kernel='rbf')\n",
    "\n",
    "# Scale features for SVR (optional, but recommended for SVM models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the SVR model\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R-squared (RÂ²)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return r_squared, mse\n",
    "\n",
    "# Evaluate Linear Regression model\n",
    "lr_r_squared, lr_mse = evaluate_model(lr_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest Regressor model\n",
    "rf_r_squared, rf_mse = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "# Evaluate SVR model (using scaled features)\n",
    "svr_r_squared, svr_mse = evaluate_model(svr_model, X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Linear Regression - R-squared: {lr_r_squared:.4f}, MSE: {lr_mse:.4f}\")\n",
    "print(f\"Random Forest Regressor - R-squared: {rf_r_squared:.4f}, MSE: {rf_mse:.4f}\")\n",
    "print(f\"SVR - R-squared: {svr_r_squared:.4f}, MSE: {svr_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, X_test, y_test):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Create scatter plot of predicted vs. actual values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)\n",
    "    plt.title(f'Predicted vs. Actual Values ({type(model).__name__})')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.show()\n",
    "\n",
    "# Plot predictions for Linear Regression model\n",
    "plot_predictions(lr_model, X_test, y_test)\n",
    "\n",
    "# Plot predictions for Random Forest Regressor model\n",
    "plot_predictions(rf_model, X_test, y_test)\n",
    "\n",
    "# Plot predictions for SVR model\n",
    "plot_predictions(svr_model, X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSet_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset:\n",
    "df2 = pd.read_csv(\"C:\\\\Users\\\\yashg\\\\OneDrive\\\\Desktop\\\\Group2\\\\INFRASTRUCTURE_FACILITIES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying top 10 rows:\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying last 10 rows\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Rows and Columns:\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints information about the DataFrame\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['State/UT'] == 'Chandigarh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see UT Chandigarh theirs is no data available for any year so we drop all the rows having State/UT 'Chandigarh':\n",
    "\n",
    "df2=df2[df2['State/UT'] != 'Chandigarh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of each column\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see many columns should be numerical like PHCs functoning on 24X7 basis', 'With Labour Room','With OT', 'With at least 4 beds'\n",
    "# But they are given as object so convert them into int\n",
    "df2[['PHCs functoning on 24X7 basis', 'With Labour Room','With OT', 'With at least 4 beds',\n",
    "   'Without Electric Supply','Without Regular Water Supply','With Telephone']] = df2[['PHCs functoning on 24X7 basis', 'With Labour Room','With OT', 'With at least 4 beds',\n",
    "   'Without Electric Supply','Without Regular Water Supply','With Telephone']].astype(int)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PHCs functioning with electricity supply and regular water supply\n",
    "df2['With Electric Supply'] = df2['Number of PHCs Functioning'] - df2['Without Electric Supply']\n",
    "df2['With Regular Water Supply'] = df2['Number of PHCs Functioning'] - df2['Without Regular Water Supply']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Null values:\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize null values in our dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df2.isnull(), cmap='viridis', cbar=False, yticklabels=False)\n",
    "plt.title('Visualization of Null Values in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying name of all fields\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Serial Number' column as it is of no use\n",
    "df2.drop('S.No.', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics for each group (fiscal year)\n",
    "grouped_data = df2.groupby('Fiscal Year')\n",
    "\n",
    "# Get descriptive statistics for each group (fiscal year)\n",
    "fiscal_year_stats = grouped_data.describe()\n",
    "\n",
    "# Print the results\n",
    "print(fiscal_year_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the total number of PHCs functioning over each fiscal year \n",
    "\n",
    "# Aggregate by fiscal year to get total number of PHCs functioning\n",
    "total_phcs_by_year = df2.groupby('Fiscal Year')['Number of PHCs Functioning'].sum()\n",
    "\n",
    "# Plotting the total number of PHCs functioning over each fiscal year using a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "total_phcs_by_year.plot(kind='bar', color='skyblue')\n",
    "plt.title('Total Number of PHCs Functioning Over Fiscal Years')\n",
    "plt.xlabel('Fiscal Year')\n",
    "plt.ylabel('Total Number of PHCs Functioning')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the change in infrastructure facilites over each fiscal year \n",
    "\n",
    "# List of facilities (columns other than 'State/UT' and 'Fiscal Year')\n",
    "facilities = ['PHCs functoning on 24X7 basis', 'With Labour Room', 'With OT',\n",
    "              'With at least 4 beds', 'Without Electric Supply',\n",
    "              'Without Regular Water Supply', 'With Telephone']\n",
    "\n",
    "# Plotting each facility's total number over each fiscal year using bar plots\n",
    "\n",
    "for i, facility in enumerate(facilities, 1):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    total_facility_by_year = df2.groupby('Fiscal Year')[facility].sum()\n",
    "    total_facility_by_year.plot(kind='bar', color='skyblue')\n",
    "    plt.title(f'Total {facility} Over Fiscal Years')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel(f'Total {facility}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visluaizing number of PHCs functioning over Fiscal Years for each state/ut:\n",
    "# Get unique State/UT names\n",
    "states = df2['State/UT'].unique()\n",
    "\n",
    "# Plotting separate line plots for each State/UT with sorted fiscal years\n",
    "for state in states:\n",
    "    state_data = df2[df2['State/UT'] == state]\n",
    "    state_data_sorted = state_data.sort_values(by='Fiscal Year')  # Sort data by fiscal year\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(state_data_sorted['Fiscal Year'], state_data_sorted['Number of PHCs Functioning'],\n",
    "             marker='o', linestyle='-', color='b')\n",
    "    plt.title(f'Number of PHCs Functioning Over Fiscal Years - {state}')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel('Number of PHCs Functioning')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From above visulalizations we can see for some states there is a data missing \n",
    "# for some particular year and they have filled with 0. \n",
    "# To address the issue of missing or zero values in specific columns for \n",
    "# certain states and fiscal years, you can replace these zeros with NaN (NULL) values\n",
    "# and then fill these missing values with the mean of the corresponding data for the\n",
    "# same state over fiscal years. This process helps to impute missing values based on the\n",
    "# average behavior of the data within each state. \n",
    "\n",
    "# Columns of interest for zero replacement and imputation\n",
    "columns_of_interest = ['Number of PHCs Functioning', 'PHCs functoning on 24X7 basis', \n",
    "                       'With Labour Room', 'With OT', 'With at least 4 beds', \n",
    "                       'With Electric Supply', 'With Regular Water Supply','With Telephone']\n",
    "\n",
    "# Replace 0 values with NaN (NULL) for specified columns\n",
    "df2[columns_of_interest] = df2[columns_of_interest].replace(0, np.nan)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()*100/len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize null values in our dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(df2.isnull(), cmap='viridis', cbar=False, yticklabels=False)\n",
    "plt.title('Visualization of Null Values in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean of the same state over fiscal years for specified columns\n",
    "df2[columns_of_interest] = df2.groupby('State/UT', group_keys=False)[columns_of_interest].apply(lambda group: group.fillna(group.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of PHCs functioning with labour room\n",
    "df2['Percentage with Labour Room'] = (df2['With Labour Room'].astype(int) * 100) / df2['Number of PHCs Functioning']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df2['Percentage with Labour Room'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter states with less than 50% of PHCs with labour room for each fiscal year\n",
    "filtered_df = df2[df2['Percentage with Labour Room'] < 50]\n",
    "\n",
    "# Group filtered DataFrame by fiscal year and list states with less than 50% labour room\n",
    "result = (filtered_df.groupby(['Fiscal Year', 'State/UT'])\n",
    "          .agg({'Percentage with Labour Room': 'mean'})\n",
    "          .reset_index())\n",
    "\n",
    "# Display the states with less than 50% labour room for each fiscal year\n",
    "for year, group_df in result.groupby('Fiscal Year'):\n",
    "    print(f\"For Fiscal Year {year}:\")\n",
    "    for index, row in group_df.iterrows():\n",
    "        print(f\"- State/UT: {row['State/UT']}, Percentage with Labour Room: {row['Percentage with Labour Room']:.2f}%\")\n",
    "    print()  # Print empty line for separation between fiscal years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter states with more than 95% of PHCs with labour room for each fiscal year\n",
    "filtered_df = df2[df2['Percentage with Labour Room'] > 95]\n",
    "\n",
    "# Group filtered DataFrame by fiscal year and list states with less than 50% labour room\n",
    "result = (filtered_df.groupby(['Fiscal Year', 'State/UT'])\n",
    "          .agg({'Percentage with Labour Room': 'mean'})\n",
    "          .reset_index())\n",
    "\n",
    "# Display the states with less than 50% labour room for each fiscal year\n",
    "for year, group_df in result.groupby('Fiscal Year'):\n",
    "    print(f\"For Fiscal Year {year}:\")\n",
    "    for index, row in group_df.iterrows():\n",
    "        print(f\"- State/UT: {row['State/UT']}, Percentage with Labour Room: {row['Percentage with Labour Room']:.2f}%\")\n",
    "    print()  # Print empty line for separation between fiscal years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group DataFrame by fiscal year and state/UT\n",
    "grouped_df = df2.groupby(['Fiscal Year', 'State/UT'])\n",
    "\n",
    "# Identify states with the highest and lowest number of PHCs functioning for each fiscal year\n",
    "max_phcs_functioning = grouped_df['Number of PHCs Functioning'].max().reset_index()\n",
    "min_phcs_functioning = grouped_df['Number of PHCs Functioning'].min().reset_index()\n",
    "\n",
    "# Identify states with the highest and lowest number of PHCs functioning on 24X7 basis for each fiscal year\n",
    "max_phcs_24x7 = grouped_df['PHCs functoning on 24X7 basis'].max().reset_index()\n",
    "min_phcs_24x7 = grouped_df['PHCs functoning on 24X7 basis'].min().reset_index()\n",
    "\n",
    "# Print results for highest and lowest number of PHCs functioning\n",
    "print(\"States with the highest number of PHCs functioning:\")\n",
    "\n",
    "print(max_phcs_functioning.loc[max_phcs_functioning.groupby('Fiscal Year')['Number of PHCs Functioning'].idxmax()])\n",
    "\n",
    "print(\"\\nStates with the lowest number of PHCs functioning:\")\n",
    "print(min_phcs_functioning.loc[min_phcs_functioning.groupby('Fiscal Year')['Number of PHCs Functioning'].idxmin()])\n",
    "\n",
    "# Print results for highest and lowest number of PHCs functioning on 24X7 basis\n",
    "print(\"\\nStates with the highest number of PHCs functioning on 24X7 basis:\")\n",
    "print(max_phcs_24x7.loc[max_phcs_24x7.groupby('Fiscal Year')['PHCs functoning on 24X7 basis'].idxmax()])\n",
    "\n",
    "print(\"\\nStates with the lowest number of PHCs functioning on 24X7 basis:\")\n",
    "print(min_phcs_24x7.loc[min_phcs_24x7.groupby('Fiscal Year')['PHCs functoning on 24X7 basis'].idxmin()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of health centers without both electric supply and regular water supply \n",
    "# in the line plot for each state over fiscal years,\n",
    "\n",
    "# Iterate over unique states and create individual graphs\n",
    "for state in df2['State/UT'].unique():\n",
    "    state_df = df2[df2['State/UT'] == state]\n",
    "    \n",
    "    # Sort state_df by 'Fiscal Year'\n",
    "    state_df = state_df.sort_values(by='Fiscal Year')\n",
    "    \n",
    "    # Plotting the line plot for the current state\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x='Fiscal Year', y='Without Electric Supply', data=state_df, label='Without Electric Supply')\n",
    "    sns.lineplot(x='Fiscal Year', y='Without Regular Water Supply', data=state_df, label='Without Regular Water Supply')\n",
    "    \n",
    "    plt.title(f'Availability of Health Centers without Essential Supplies in {state}')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel('Count of Health Centers')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Fiscal Year' and calculate the sum of each column\n",
    "yearly_totals = df2.groupby('Fiscal Year').sum(numeric_only=True)\n",
    "\n",
    "# Plotting line plots for each column over fiscal years\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Iterate over each column and plot a line\n",
    "for column in ['Number of PHCs Functioning',\"PHCs functoning on 24X7 basis\",\n",
    "               'With Labour Room', 'With OT', 'With at least 4 beds','With Electric Supply','With Regular Water Supply']:\n",
    "    plt.plot(yearly_totals.index, yearly_totals[column], label=column)\n",
    "\n",
    "plt.title('Change in Health Center Facilities over Fiscal Years')\n",
    "plt.xlabel('Fiscal Year')\n",
    "plt.ylabel('Total Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the changes in infrastructure facilities over fiscal years for each state \n",
    "\n",
    "\n",
    "# Get unique list of State/UTs\n",
    "states = df2['State/UT'].unique()\n",
    "\n",
    "# Iterate over each State/UT and plot infrastructure trends\n",
    "for state in states:\n",
    "    state_df = df2[df2['State/UT'] == state]\n",
    "    \n",
    "    \n",
    "    # Sort the DataFrame by fiscal years in ascending order\n",
    "    state_df = state_df.sort_values(by='Fiscal Year')\n",
    "    \n",
    "    # Extract fiscal years and infrastructure parameters\n",
    "    fiscal_years = state_df['Fiscal Year']\n",
    "    parameters = state_df.columns.difference(['State/UT', 'Fiscal Year','Without Electric Supply', 'Without Regular Water Supply'])\n",
    "    \n",
    "    # Plotting the changes in infrastructure facilities over fiscal years (ascending order)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for param in parameters:\n",
    "        plt.plot(fiscal_years, state_df[param], label=param, marker='o', linestyle='-')\n",
    "    \n",
    "    plt.title(f'Changes in Infrastructure Facilities Over Fiscal Years - {state}')\n",
    "    plt.xlabel('Fiscal Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.xticks(fiscal_years)  # Set x-axis ticks to fiscal years\n",
    "    # Place the legend outside the plot area\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distrution of functioning PHCs among various states over different fiscal years:\n",
    "\n",
    "grouped_data = df2.groupby('Fiscal Year')\n",
    "\n",
    "# Create a separate bar graph for each fiscal year\n",
    "for fiscal_year, group_df in grouped_data:\n",
    "    plt.figure(figsize=(25, 6))\n",
    "    sns.barplot(x='State/UT', y='Number of PHCs Functioning', data=group_df)\n",
    "    plt.title(f'Distribution of Functioning PHCs in Fiscal Year {fiscal_year}')\n",
    "    plt.xlabel('State/UT')\n",
    "    plt.ylabel('Number of PHCs Functioning')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'State/UT' and 'Fiscal Year' to calculate total PHCs functioning\n",
    "state_year_grouped = df2.groupby(['State/UT', 'Fiscal Year'])['Number of PHCs Functioning'].sum().reset_index()\n",
    "\n",
    "# Get top 10 states based on total PHCs functioning across all years\n",
    "top_states = state_year_grouped.groupby('State/UT')['Number of PHCs Functioning'].sum().nlargest(10).index.tolist()\n",
    "\n",
    "# Combine all other states into 'Others'\n",
    "state_year_grouped['State/UT'] = state_year_grouped['State/UT'].apply(lambda x: x if x in top_states else 'Others')\n",
    "state_year_grouped = state_year_grouped.groupby(['State/UT', 'Fiscal Year'])['Number of PHCs Functioning'].sum().reset_index()\n",
    "\n",
    "# Color palette for pie chart\n",
    "colors = sns.color_palette('tab10')\n",
    "\n",
    "# Iterate over each fiscal year and plot pie chart\n",
    "for year in df2['Fiscal Year'].unique():\n",
    "    year_data = state_year_grouped[state_year_grouped['Fiscal Year'] == year]\n",
    "    \n",
    "    labels = year_data['State/UT'].tolist()\n",
    "    sizes = year_data['Number of PHCs Functioning'].tolist()\n",
    "    \n",
    "    # Plotting the pie chart\n",
    "    plt.figure(figsize=(5, 8))\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140,colors=colors)\n",
    "    plt.title(f'Distribution of PHCs Functioning by State in {year}')\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each state and create separate side-by-side bar charts\n",
    "for state in df2['State/UT'].unique():\n",
    "    state_data = df2[df2['State/UT'] == state]\n",
    "    fiscal_years = state_data['Fiscal Year'].unique()\n",
    "\n",
    "    # Set up the figure and axes for the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # Define the width of each bar (adjust as needed)\n",
    "    bar_width = 0.15\n",
    "    index = range(len(fiscal_years))\n",
    "\n",
    "    # Plotting each parameter as a separate set of bars\n",
    "    ax.bar(index, state_data['Number of PHCs Functioning'], width=bar_width, label='PHCs Functioning')\n",
    "    ax.bar([p + bar_width for p in index], state_data['PHCs functoning on 24X7 basis'], width=bar_width, label='PHCs Functioning 24*7')\n",
    "    ax.bar([p + 2*bar_width for p in index], state_data[\"With Labour Room\"], width=bar_width, label='With Labour Room')\n",
    "    ax.bar([p + 3*bar_width for p in index], state_data[\"With OT\"], width=bar_width, label='With OT')\n",
    "    ax.bar([p + 4*bar_width for p in index], state_data[\"With at least 4 beds\"], width=bar_width, label='With at least 4 beds')\n",
    "\n",
    "    # Customize the plot\n",
    "    ax.set_xlabel('Fiscal Year')\n",
    "    ax.set_ylabel('Number of PHCs')\n",
    "    ax.set_title(f'Variation of Parameters Over Fiscal Years - {state}')\n",
    "    ax.set_xticks([p + 1.5*bar_width for p in index])\n",
    "    ax.set_xticklabels(fiscal_years)\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot for the current state\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for analysis\n",
    "columns_of_interest = ['Number of PHCs Functioning', 'PHCs functoning on 24X7 basis', \n",
    "                       'With Labour Room', 'With OT', 'With at least 4 beds','With Electric Supply',\n",
    "           'With Regular Water Supply', 'With Telephone']\n",
    "\n",
    "# Pairplot for multivariate analysis (scatter plots)\n",
    "sns.pairplot(df2[columns_of_interest], kind='scatter', diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Infrastructure Facilities', y=1.02)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix heatmap\n",
    "correlation_matrix = df2[columns_of_interest].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Correlation Matrix of Infrastructure Facilities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  perform one-hot encoding on categorical columns\n",
    "categorical_columns = ['State/UT', 'Fiscal Year']\n",
    "\n",
    "# Perform One-Hot Encoding using pd.get_dummies()\n",
    "df_encoded = pd.get_dummies(df2, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Display the encoded DataFrame\n",
    "print(\"Encoded DataFrame:\")\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Extract features (columns to be scaled)\n",
    "numerical_columns = ['Number of PHCs Functioning','PHCs functoning on 24X7 basis','With Labour Room','With OT','With at least 4 beds','Without Electric Supply','Without Regular Water Supply','With Telephone',\n",
    "                    'With Electric Supply','With Regular Water Supply']\n",
    "# Perform standardization\n",
    "scaler = StandardScaler()\n",
    "df_encoded[numerical_columns] = scaler.fit_transform(df_encoded[numerical_columns])\n",
    "df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Fiscal Year' column to datetime format with explicit date format\n",
    "df2['Fiscal Year'] = pd.to_datetime(df2['Fiscal Year'], format='%Y-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Grouping Features\n",
    "# Grouping States/UTs into regions based on geographical location or any other criteria\n",
    "north_states = ['Delhi', 'Haryana', 'Himachal Pradesh', 'Jammu and Kashmir', 'Punjab', 'Rajasthan', 'Uttarakhand', 'Uttar Pradesh']\n",
    "south_states = ['Andhra Pradesh', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Telangana']\n",
    "east_states = ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal']\n",
    "west_states = ['Goa', 'Gujarat', 'Maharashtra']\n",
    "central_states = ['Chhattisgarh', 'Madhya Pradesh']\n",
    "northeast_states = ['Arunachal Pradesh', 'Assam', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Sikkim', 'Tripura']\n",
    "\n",
    "# Creating a new column 'Region' based on the grouping\n",
    "df2['Region'] = np.where(df2['State/UT'].isin(north_states), 'North India',\n",
    "                         np.where(df2['State/UT'].isin(south_states), 'South India',\n",
    "                                  np.where(df2['State/UT'].isin(east_states), 'East India',\n",
    "                                           np.where(df2['State/UT'].isin(west_states), 'West India',\n",
    "                                                    np.where(df2['State/UT'].isin(central_states), 'Central India',\n",
    "                                                             np.where(df2['State/UT'].isin(northeast_states), 'Northeast India', 'Other'))))))\n",
    "\n",
    "# Step 6: Temporal Features\n",
    "\n",
    "# Convert 'Fiscal Year' column to datetime format\n",
    "df2['Fiscal Year'] = pd.to_datetime(df2['Fiscal Year'])\n",
    "\n",
    "# You can inspect the modified DataFrame to see the changes\n",
    "print(df2.head())\n",
    "\n",
    "df2['Year'] = df2['Fiscal Year'].dt.year\n",
    "\n",
    "# You can inspect the modified DataFrame to see the new features\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df2.drop(['State/UT', 'Fiscal Year','Region','Without Electric Supply', 'Without Regular Water Supply'], axis=1)\n",
    "corr_matrix = features.corr()\n",
    "corr_with_target = corr_matrix['With Labour Room'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Step 4: Select Features\n",
    "selected_features = corr_with_target[corr_with_target > 0.5].index.tolist()\n",
    "\n",
    "# Step 5: Visualize Correlation\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"Important features based on correlation analysis:\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features and target variable\n",
    "X = df_encoded[['Number of PHCs Functioning', 'PHCs functoning on 24X7 basis', 'With OT', 'With at least 4 beds',\n",
    "          'With Electric Supply', 'With Regular Water Supply', 'With Telephone']]\n",
    "y = df_encoded['With Labour Room']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs Predicted PHCs functioning 24X7\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize SVR model\n",
    "svr_model = SVR(kernel='rbf')\n",
    "\n",
    "# Scale features for SVR (optional, but recommended for SVM models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the SVR model\n",
    "svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate R-squared (RÂ²)\n",
    "    r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate Mean Squared Error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return r_squared, mse\n",
    "\n",
    "# Evaluate Linear Regression model\n",
    "lr_r_squared, lr_mse = evaluate_model(lr_model, X_test, y_test)\n",
    "\n",
    "# Evaluate Random Forest Regressor model\n",
    "rf_r_squared, rf_mse = evaluate_model(rf_model, X_test, y_test)\n",
    "\n",
    "# Evaluate SVR model (using scaled features)\n",
    "svr_r_squared, svr_mse = evaluate_model(svr_model, X_test_scaled, y_test)\n",
    "\n",
    "print(f\"Linear Regression - R-squared: {lr_r_squared:.4f}, MSE: {lr_mse:.4f}\")\n",
    "print(f\"Random Forest Regressor - R-squared: {rf_r_squared:.4f}, MSE: {rf_mse:.4f}\")\n",
    "print(f\"SVR - R-squared: {svr_r_squared:.4f}, MSE: {svr_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, X_test, y_test):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Create scatter plot of predicted vs. actual values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)\n",
    "    plt.title(f'Predicted vs. Actual Values ({type(model).__name__})')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.show()\n",
    "\n",
    "# Plot predictions for Linear Regression model\n",
    "plot_predictions(lr_model, X_test, y_test)\n",
    "\n",
    "# Plot predictions for Random Forest Regressor model\n",
    "plot_predictions(rf_model, X_test, y_test)\n",
    "\n",
    "# Plot predictions for SVR model\n",
    "plot_predictions(svr_model, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
